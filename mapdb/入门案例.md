## MapDB

Mapdb 是一种内存类型数据库，支持堆存储、文件存储、堆外存储等等，还支持MVCC 以及 事务等特性，MapDB的核心类分别为DBMarker 与 DB 类，

DBMarker 主要用于创建 各种类型的DB（可以理解为数据库，单并不是） 比如 fileDB

DB 代表数据库的意思，主要用于创建各种集合包括map类型，以及支持过期失效，过期刷新等等



### 入门示例

案例1：

```java
//创建一个文件类型的数据存储
DB db = DBMaker.fileDB(new File("")).make();
```



案例2：通过db创建数据类型

```java
NavigableSet<?> navigableSet = db
        .treeSet("treeSet")
        .maxNodeSize(112)
        .serializer(Serializer.STRING)
        .createOrOpen();
```



DB可以以三种不同的方式来创建数据类型

构建器可以以三种不同的方法结束：

- `create()` 创建新的集合，如果集合已经存在，则引发异常
- `open()` 打开现有集合，如果不存在则抛出异常
- `createOrOpen()` 打开现有集合（如果存在），否则创建它。



DB 不限于集合类型，还可以用来创建其他类型数据，例如Atomic Records

```java
Atomic.Var<Person> var = db.atomicVar("mainPerson",Person.SERIALIZER).createOrOpen();
```



### 事务支持

DB 分别用  `commit()`，`rollback()`和`close()` 用来处理事务的生命周期

一个DB 对象代表一个事务，可以对该db上创建出来的数据类型做事务操作，示例如下：

```java

DB db = DBMaker
    .memoryDB()
    .concurrencyScale(4)
    .transactionEnable()
    .closeOnJvmShutdown()
    .make();

ConcurrentNavigableMap<Integer, String> map = db
     .treeMap("collectionName", Serializer.INTEGER, Serializer.STRING)
     .createOrOpen();


ConcurrentNavigableMap<Integer, String> map1 = db
      .treeMap("collectionName1", Serializer.INTEGER, Serializer.STRING)
      .createOrOpen();


map.put(1, "one");
map.put(2, "two");
//map.keySet() is now [1,2] even before commit

db.commit();  //persist changes into disk

map.put(3, "three");
map1.put(1,"one");
//map.keySet() is now [1,2,3]
//map.keySet() is now [1]

db.rollback(); //revert recent changes
//map.keySet() is now [1,2]
//map1.keySet() is now []

db.close();
```



### HTreeMap

HTreeMap 提供了 HashMap 与 HashSet 两种类型的集合，它可以控制数据缓存到期的时间， 在并发更新的场景下他是线程安全的 

 线程安全性方面，通过使用多个段来支持并行写入，每个段具有单独的ReadWriteLock。JDK 7中的ConcurrentHashMap 以类似的方式工作。段的数量（也称为并发因子）是可配置的。 

 HTreeMap是一个分段哈希树。与其他HashMaps不同，它不使用固定大小的哈希表，并且在哈希表增长时不会重新哈希编码所有数据。HTreeMap使用自动扩展索引树，所以它不需要调整大小。它也占用较少的空间，因为空哈希槽不消耗任何空间。另一方面，树结构需要更多的寻求，在访问速度稍慢一些。 

HTreeMap可选地基于四个条件支持条目到期：最大映射大小，最大存储大小，自上次修改以来的生存时间和自上次访问以来的生存时间。过期的条目将自动删除。此功能使用FIFO队列，并且每个段都有独立的到期队列。

 HTreeMap可以根据四个条件可选地支持条目过期：最大map大小，最大存储大小，自上次修改以来的生存时间以及自上次访问以来的生存时间。过期条目将自动删除。此功能使用FIFO队列，每个段都有独立的过期队列。 



## 串行化

HTreeMap有很多参数。最重要的是name，它用来标识数据库对象内的Map 和处理Map中数据的序列化：

```java
HTreeMap<String, Long> map = 
    db.hashMap("name_of_map").
    keySerializer(Serializer.STRING).
    create();

//or shorter form 
HTreeMap<String, Long> map2 = 
    db.hashMap("some_other_map", Serializer.STRING, Serializer.LONG).
    create();
```

也可以跳过序列化器定义，但是MapDB将使用较慢的通用序列化，不建议这样做：

```java
HTreeMap map = db.hashMap("name_of_map").create();
```

推荐使用HTreeMap处理大键/值。在同样的情况下，您可能需要使用压缩。可以启用压缩存储范围，但是有一些开销。相反，最好将压缩应用于键或值上的特定序列化器。这是通过使用serializer wrapper来完成的：

```java
HTreeMap<Long, String> map = 
    db.hashMap("map").
        valueSerializer(new SerializerCompressionWrapper(Serializer.STRING)).
        create()
```





## 哈希编码

大多数哈希映射使用由Object.hashCode（）生成的32位哈希值，并检查其相等性
Object.equals（other）。但是很多类（byte [] ，int [] ）不能正确实现。
MapDB使用Key Serializer生成哈希码并比较键。例如，如果使用Serializer.BYTE_ARRAY 作为键序列化器，byte [] 可以直接用作HTreeMap中的键：

```java
HTreeMap<byte[], Long> map = 
    db.hashMap("map").
    keySerializer(Serializer.BYTE_ARRAY).
    valueSerializer(Serializer.LONG).
    create();
```

另一个问题是在一些类中的hashCode（）是弱的，它会导致冲突并降低性能。String.hashCode（）是弱的，但是是规范的一部分，所以它不能被改变。

JDK中的HashMap 以牺牲内存和性能开销为代价实现了许多解决方法。HTreeMap 没有这样的解决方法，而弱Hash将会大大减缓。
相反，HTreeMap 正在修复问题的根源，Serializer.STRING 使用更强的XXHash，这会产生较少的冲突。String.hashCode（）仍然可用，但使用不同的序列化程序：

```java
//this will use strong XXHash for Strings 
HTreeMap<String, Long> map = db.hashMap("map")
// by default it uses strong XXHash
.keySerializer(Serializer.STRING)
.valueSerializer(Serializer.LONG)
.create();

//this will use weak `String.hashCode()` 
HTreeMap<String, Long> map2 = db.hashMap("map2")
// use weak String.hashCode()
.keySerializer(Serializer.STRING_ORIGHASH)
.valueSerializer(Serializer.LONG)
.create();
```

哈希MAP容易受到哈希碰撞攻击。HTreeMap 增加了Hash Seed的保护。在创建集合时随机生成，并与其定义一起保持。用户还可以提供自己的哈希种子：

```java
HTreeMap<String, Long> map = 
    db.hashMap("map", Serializer.STRING, Serializer.LONG)
    .hashSeed(111) //force Hash Seed value
    .create();
```



### DB 常用方法

- keySerializer mapKey的序列化器
- valueSerializer mapValue的序列化器
- SerializerCompressionWrapper 压缩序列化后的结果
- hashSeed  使用自定义hash种子
-  counterEnable   开启实时计数器
-  memoryShardedHashMap    每个分段独立存储 ，支持更高的并发性能
-  expireAfterUpdate  在上次修改更新后多长时间内过期
-  expireAfterCreate   在创建后多长时间内过期
-  expireAfterGet   上次获取后1分钟 删除 

- 组合 （在存储容量多大后 再次获取将过期）
  -  .expireStoreSize(16 * 1024*1024*1024)      
  -   .expireAfterGet() 

- 组合 （在超出集合大小多少后，再次获取获取）

  -  expireMaxSize(128) 
  -  expireAfterGet 

-  expireAfterUpdate(1000)  待定

  

-  expireMaxSize（200） 超过多大的集合空间将过期

  -  有三个触发条件将数据放入到过期队列：
    `expireAfterCreate()` `expireAfterUpdate()` 和 `expireAfterGet()` 主要没有参数 

- expireCompactThreshold(0.4)    //当空余空间大于40% 就启动压缩        .